Type: linkpost
Title: Misunderstood Technology
Link: https://www.regulus.com/blog/tesla-model-3-spoofed-off-the-highway-regulus-researches-hack-navigation-system-causing-car-to-steer-off-road/
Pubdate: 2019/07/11 17:21:21
Author: Zac J. Szewczyk

Although a few weeks old now, I still think addressing this may have some enduring value.

Regulus Cyber got some attention a few weeks back for tricking a Tesla Model 3 into making a premature turn. Not an unsafe one, just premature. I almost didn't read the post, though, let alone write about it, because *of course* you can trick a Tesla into turning early. [The](https://news.ycombinator.com/item?id=20235151) article's [popularity](https://lobste.rs/s/la10ax/tesla_model_3_spoofed_off_highway) made me come around, though, and so here we are. Evidently this is still 1) surprising, and 2) interesting, and I would like to address both of those here.  

Let's tackle #1 first. This does not surprise me because at best, autonomous systems will drive as well as you do on an unfamiliar country road at night. Consider that scenario: you can see no more than a few feet ahead, know nothing about the road beyond your headlights, and have nothing but a questionable GPS route to guide you through the darkness. At any moment something could jump into your path, or you could find your way blocked by something no map will ever identify. These conditions are the human equivalent of the conditions under which the autonomous Tesla system operates at all times. Given that, *of course* Regulus Cyber tricked it into turning early.

Put yourself in that scenario. If you found yourself on an unfamiliar country road in the middle of the night, able to see maybe twenty feet ahead of you and navigating with a GPS that said to turn in a mile, would you turn early, onto another *road*, if that GPS told you to? I would. And that's why this is neither surprising nor interesting to me, and why it should be neither to you as well. Of course you can trick a Tesla into turning early, because you could trick me into doing it, too. Instead of focusing on the weird edge cases where this miraculous technology fails(?) by doing the same thing a human would, how about we focus on all the [lives](https://interestingengineering.com/5-times-elon-musk-and-teslas-autopilot-saved-their-drivers-bacon) it saved [driving](https://electrek.co/2019/02/05/tesla-owner-autopilot-saves-life-swerving/) [better](https://interestingengineering.com/tesla-autopilot-saved-lives-of-family-says-driver) than we do?

On the topic of misunderstood technology, I have another point to make about the ridiculous notion of "planned obsolescence"--but I will leave that for another day.
