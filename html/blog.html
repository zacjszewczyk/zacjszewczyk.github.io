<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="author" content="Zac Szewczyk">
        <meta name="application-name" content="Zac Szewczyk">
        <meta name="keywords" content="Zac Szewczyk, Zachary Szewczyk, Zac J. Szewczyk, Szewczyk, zacjszewczyk">
        <meta name="description" content="Zac Szewczyk's Blog">
        
        <meta name="robots" content="index, follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover"> 
        <meta name="referrer" content="no-referrer">
        <meta name="theme-color" content="#FFFFFF">
        <link rel="stylesheet" href="/assets/main.css">
        
        <meta property="og:image" content="/assets/images/favicon.ico">
        <meta property="og:title" content="Blog - Zac Szewczyk">
        <meta property="og:site_name" content="Zac Szewczyk's Blog">
        <meta property="og:article:author" content="Zac Szewczyk">
        <meta property="og:see_also" content="https://zacs.site/">

        <link rel="alternate" type="application/rss+xml" title="Zac Szewczyk's Feed" href="/rss.xml">
        <link rel="shortcut icon" type="image/ico" size="16x16" href="/assets/images/favicon.ico">
        <link rel="shortcut icon" type="image/ico" size="192x192" href="/assets/images/favicon_192.ico">
        <link rel="shortcut icon" type="image/ico" size="512x512" href="/assets/images/favicon_512.ico">
        
        <title>Blog - Zachary Szewczyk</title>
    </head>
    <body id="blog">
        <nav>
            <a href="/index.html" id="home_link">Home</a>
            <a href="/blog.html" id="blog_link">Blog</a>
            <a href="/explore.html" id="explore_link">Explore</a>
            <a href="/rss.xml" id="rss_link">RSS</a>
            <a href="/archives.html" id="archives_link" rel="prefetch">Post Archives</a>
            <a href="/projects.html" id="projects_link">Projects</a>
            <a href="/disclaimers.html" id="disclaimers_link">Disclaimers</a>
        </nav>
        <main>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://mondaynote.com/arm-ed-mac-we-have-an-answer-545a20419a46">ARM Macs</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-24 13:22:21-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/24 13:22:21 EST</time>
<p>Jean-Louis Gassee, in <a href="https://mondaynote.com/arm-ed-mac-we-have-an-answer-545a20419a46">yesterday&#8217;s Monday Note</a>:</p>

<blockquote>
<p>&#8220;An answer to the now age-old ARM-ed Mac question now emerges: With the emphasis on the iPad Pro as a real computer, there&#8217;s no reason for Apple to move the Mac off of trusty if perhaps less glamorous Intel processors.&#8221;</p>
</blockquote>

<p>If I may finish his sentence, &#8220;... there&#8217;s no reason for Apple to move the Mac off of trusty if perhaps less glamorous Intel processors, <em>because the iPad will soon replace the Mac</em>.&#8221; As for when this will happen, I don&#8217;t know&#160;&#8212;&#160;and if Jean-Louis does, he&#8217;s not saying. With each passing year it becomes more feasible from a technical standpoint, but it will take a sea change in Apple&#8217;s strategic thinking for this to actually happen.</p>

<p>This reminds me of the electric car situation: they have gotten pretty good, but <a href="https://zacs.site/blog/expediton-vehicles.html">at least for my use case</a>, <a href="https://zacs.site/blog/my-electric-vehicle-wish-list.html">they aren&#8217;t quite good enough</a>. I can see that this will change soon, but&#160;&#8212;&#160;again&#160;&#8212;&#160;it will take a sea change in strategic thinking to make this happen. In this case, that means automakers stop trying to turn a truck into an electric truck, and start designing vehicles to take full advantage of all this new technology enables.</p>

<p>As I start shopping around to replace my trusty 2013 MacBook Pro, I hope Apple will make its decision soon.</p>


<p><a class='read_more_link' href='/blog/arm-macs.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://medium.com/@okaleniuk/premature-optimization-is-the-root-of-all-evil-is-the-root-of-evil-a8ab8056c6b">"Premature optimization is the root of all evil" is the root of evil</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-23 05:30:48-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/23 05:30:48 EST</time>
<p><a href="https://zacs.site/blog/linear-python.html">As I have said before</a>, I believe in premature optimization. It leads to better products in the long run, and if optimized along the proper vectors, more secure ones, too. It&#8217;s nice to see that <a href="https://medium.com/@okaleniuk/premature-optimization-is-the-root-of-all-evil-is-the-root-of-evil-a8ab8056c6b">Oleksandr Kaleniuk agrees</a>.</p>


<p><a class='read_more_link' href='/blog/the-root-of-all-evil.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://rap.mirror.cyberbits.eu/fosdem/2020/K.1.105/kernel_address_space_isolation.webm">Containers are Not the Future</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-20 08:43:18-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/20 08:43:18 EST</time>
<p>Ian Eyberg in <a href="https://rap.mirror.cyberbits.eu/fosdem/2020/K.1.105/kernel_address_space_isolation.webm"><em>Containers are Not the Future</em></a>, quoting a line from <a href="https://rap.mirror.cyberbits.eu/fosdem/2020/K.1.105/kernel_address_space_isolation.webm">Mike Rapoport and James Bottomley&#8217;s talk at this year&#8217;s Free and Open source Software Developers&#8217; European Meeting</a>:</p>

<blockquote>
<p>&#8220;The kernel developers view of the docker community is that in the rare case they can actually formulate the question correctly they usually don&#8217;t understand the answer.&#8221;</p>
</blockquote>

<p>Hilarious. Ian also got at a critical point about the state of modern software engineers, something I touched on a few weeks ago when I linked to <a href="https://zacs.site/blog/good-times-create-weak-men.html"><em>Good TImes Create Weak Men</em></a>. Short-term, push-button fixes attempt to get around the long, hard, and expensive problem of developing and deploying expertise. Like outsourcing, while the former approach has <a href="http://berthub.eu/articles/posts/national-outsourcing/">short-term benefits</a>, its <a href="https://pdfs.semanticscholar.org/e9da/f5cc1c94c6e34e29095ca168e8fa2d750df9.pdf">long-term effects are debilitating</a>.</p>


<p><a class='read_more_link' href='/blog/containers-are-not-the-future.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/when-things-go-wrong.html">You Earn Your Pay When Things Go Wrong</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-19 07:24:17-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/19 07:24:17 EST</time>
<p>Dan Moore&#8217;s 2018 post, <a href="http://www.mooreds.com/wordpress/archives/2765"><em>When do you earn your pay?</em></a>, reminded me of something I told one of my friends a few years ago. Both senior ROTC cadets at the time, he had just finished complaining about how our instructors always blamed him when other people did the wrong thing. &#8220;You&#8217;re not here for things to go right,&#8221; I told him, &#8220;the only reason our job exists is to fix things when they go wrong.&#8221; This leads into a larger point about the role of Officers in the Army, but I need to spend more time thinking about that before I start writing about it; for now, this will have to suffice.</p>


<p><a class='read_more_link' href='/blog/when-things-go-wrong.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://www.outsideonline.com/2409983/billionaire-wilderness-wyoming-book-review">America's Richest Mountain Town is it's Most Unequal</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-11 07:29:44-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/11 07:29:44 EST</time>
<p>Heather Hansman, writing for Outside Online:</p>

<blockquote>
<p>&#8220;Americans have gone west to escape the ills of society while bringing the ills of society with them, pretty much since Manifest Destiny; one regional myth was that, once here, everyone would have the chance to experience something wild. In reality, of course, settlement always brought land-access issues, prompted human displacement, and fueled socioeconomic disparity. That remains true now, as Billionaire Wilderness makes evident through its examination of one of the most beloved playgrounds of this part of the nation.&#8221;</p>
</blockquote>

<p>It&#8217;s an interesting read.</p>


<p><a class='read_more_link' href='/blog/most-unequal.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://www.gkogan.co/blog/simple-systems/">Simple Systems Have Less Downtime</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-04 17:53:30-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/04 17:53:30 EST</time>
<p>Simple systems deploy faster than complex ones, and fail less often; sometimes they take less time to build, too, but the pursuit of simplicity often entails a long process to prioritize some features while justifying the exclusion of others. Ironically, that process tends to take much longer than just building in all the features, so most choose the latter approach. The end result is complex software that does many things, but few things well.</p>

<p>As a <a href="https://zacs.site/blog/linear-python.html">fan of premature optimization</a>, I like to take the opposite approach, and to take it to the extreme. <a href="/projects.html#codingProjects">My software</a>&#160;&#8212;&#160;and even my devices&#160;&#8212;&#160;tend to do one thing well. This makes the upfront cost higher in terms of time spent planning projects, writing code, and purchasing hardware, but also&#160;&#8212;&#160;since <a href="https://zacs.site/blog/good-times-create-weak-men.html">I understand and control the entire stack</a>&#160;&#8212;&#160;lowers the number of opaque systems that can fail as well as the knock-on effects of such an event. I consider this a worthwhile tradeoff, and I bet <a href="https://www.gkogan.co/blog/simple-systems/">Greg would, too</a>.</p>


<p><a class='read_more_link' href='/blog/simple-systems-have-less-downtime.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://www.lowtechmagazine.com/2013/01/mechanical-transmission-of-power-stangenkunst.html">The Mechanical Transmission of Power</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-03-02 07:37:21-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-03.html">03</a>/02 07:37:21 EST</time>
<p>As I read through <a href="https://www.lowtechmagazine.com/2013/01/mechanical-transmission-of-power-stangenkunst.html">part one</a> and then, later, parts <a href="https://www.lowtechmagazine.com/2013/02/the-mechanical-transmission-of-power-jerker-line-systems.html">two</a> and <a href="https://www.lowtechmagazine.com/2013/03/the-mechanical-transmission-of-power-3-wire-ropes.html">three</a> of Kris De Decker&#8217;s interesting series on mechanical power transmission, I knew I had read other articles from the Low-Tech Magazine before. A quick check through my archive proved me right: for those looking for other interesting reads on low-tech solutions to hard problems, check out <a href="https://www.lowtechmagazine.com/2020/01/how-sustainable-is-a-solar-powered-website.html">How Sustainable is a Solar Powered Website?</a> and <a href="https://solar.lowtechmagazine.com/2015/10/how-to-build-a-low-tech-internet/">How to Build a Low-tech Internet</a>, too, or any of <a href="https://www.lowtechmagazine.com/">The Low-Tech Magazine&#8217;s other fascinating work</a>. </p>

<p>In a similar vein, check out <a href="http://507movements.com/">507 Movements</a> for&#160;&#8212;&#160;get this&#160;&#8212;&#160;507 different mechanical mechanisms. When I run into <a href="/projects.html#caddProjects">a novel engineering challenge</a>, I always try to solve it in a simple mechanical way first. Computers are great, but there is a certain elegance to simple machinery for which I have great appreciation.</p>


<p><a class='read_more_link' href='/blog/the-mechanical-transmission-of-power.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/first-crack-release-notes-0220.html">First Crack Release Notes, February 2020</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-28 08:05:41-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/28 08:05:41 EST</time>
<p>I had a busy start to the year. Between <a href="https://zacs.site/blog/holiday-fitness.html">traveling</a> and work, I did not have enough time to finish the titanic task I had given myself: rewriting First Crack. When it came time to post the January release notes, then, I did not have anything ready; today I do.</p>

<p>First, some history&#160;&#8212;&#160;because it explains how I got here, and why I took on this task. As best I can tell, based on file creation times and git logs, I started writing First Crack around October of 2011. I worked on it here and there over the next three years, then made the source code public in July of 2014. I kept the public code base updated for about 18 months, until the end of 2015. By then I had grown enough to realize I could build a much better engine. It took me two years to make that rewrite production-ready, and then seven months to feel comfortable <a href="https://zacs.site/blog/re-introducing-first-crack.html">re-releasing it</a>. Along with that re-release, I began posting monthly updates to track the changes I made, and the ones I wanted to make in the future. These posts lasted from <a href="https://zacs.site/blog/first-crack-release-notes-0619.html">June</a> to <a href="https://zacs.site/blog/first-crack-release-notes-1219.html">December</a>, 2019. </p>

<p>I started feeling the itch to rewrite First Crack again when the new year rolled around. I had discovered Pythonic concurrency in <a href="https://zacs.site/blog/first-crack-release-notes-0819.html">August</a>, but took a serious interest in it six months later. By the time I finished <a href="https://zacs.site/blog/linear-python.html"><em>Sequential Execution, Multiprocessing, and Multithreading IO-Bound Tasks in Python</em></a>, I once again felt I had grown enough to make a rewrite worthwhile. I started that process near the end of January, with a few general goals: </p>

<ul>
<li><strong>Write good code.</strong> I had written many of First Crack&#8217;s functions in a flow state. They worked, but it took a lot to remember why they did, and few conformed to best practices. Most programmers will say only the first trait matters, but well-reasoned, well-structured, and well-written programs streamline collaboration, make maintenance easy, and help projects outlast their authors. I also consider this a point of pride: good programmers write good code; bad ones excuse it. As part of the rewrite, I wanted to focus on doing the right things well, and standardizing method names, structure, and return values.</li>
<li><strong>Write modern code.</strong> A month after First Crack&#8217;s re-release, <a href="https://zacs.site/blog/first-crack-release-notes-0719.html">I began supporting Python 2</a>. If a BASH script could not find Python 3, it changed the engine to run on the now-deprecated yet immortal version 2. The ease with which I managed this should have made obvious the fact that I had not taken advantage of years of improvements and optimizations, but that realization did not occur until I did <a href="https://zacs.site/blog/linear-python.html">a deep dive on concurrency</a>. Along with the improvements outlined in the bullet above, I also wanted to modernize my code as part of this rewrite. As I think back to the beginning of this process, <a href="https://www.fluentcpp.com/2020/01/17/technical-debt-is-like-a-tetris-game/">this cautionary tale</a> and <a href="https://blog.digitalocean.com/from-15-000-database-connections-to-under-100-digitaloceans-tale-of-tech-debt/">this story of redemption</a> likely played a part in setting this goal as well. </li>
<li><strong>Design for concurrency.</strong> <a href="https://zacs.site/blog/linear-python.html">My deep dive into concurrency</a> made its value clear. Although I had managed to bolt on some multiprocessing methods back in <a href="https://zacs.site/blog/first-crack-release-notes-0819.html">August of 2019</a>, First Crack did not take full advantage of multiprocessing or multithreading. I wanted to use this rewrite as an opportunity to take full advantage of both.</li>
</ul>

<p>I began the rewrite with these goals in mind, for both the back-end engine and the front-end design. I got the lion&#8217;s share of the work done over a long weekend at the beginning of February, and then spent the rest of the month cleaning up and documenting the code base, and polishing the new site layout. Check out the rewritten engine at <a href="https://github.com/zacjszewczyk/FirstCrack-Public">FirstCrack&#8217;s GitHub page</a>, and the new design here.</p>

<p>Aside from pursuing the goals above, for the most part First Crack&#8217;s rewrite just tries to do everything its predecessor did but better&#160;&#8212;&#160;with one exception: the preview feature now sets up a local web server to better replicate an actual use case scenario. Running <code>blog.py</code> with the <code>-p</code> flag&#160;&#8212;&#160;or using <code>make preview</code>&#160;&#8212;&#160;creates a private web server available to the local machine only, so just you can test your website at <code>http://localhost:8000</code>; the <code>-P</code> flag&#160;&#8212;&#160;or <code>make public</code>&#160;&#8212;&#160;creates a public one available to anyone on the network via port 8000. Use the latter to test your website on other devices, for example, or show off a new design to your coworkers. Keep in mind, though, that <a href="https://jameshfisher.com/2019/05/26/i-can-see-your-local-web-servers/">the latter option may give bad actors a way into your machine</a>; I implemented only the most basic security controls, so use this feature on shared networks with caution. The accompanying log file First Crack generates, <code>server.log</code>, may help track down evidence of malicious activity if it feels like something went awry.</p>

<p>Those who have used Firebase before may know that the command-line tool can do this with <code>firebase serve</code>, but Firebase&#8217;s web server does not afford me the same level of control a custom implementation does. It&#8217;s also slow, so I wrote my own.</p>

<p>I still have work to do. First Crack&#8217;s initial rewrite runs about 50% slower than its predecessor, so I need to spend some time fine-tuning it. While I had all but exhausted all avenues for better performance in the old version, I have not done much of that work in the new one; I look forward to making progress here soon. After that, I plan to overhaul the Markdown parser, as outlined below.</p>

<h2 class="headers" id="FeatureRoadmap">Feature Roadmap<span>&nbsp;<a href="#FeatureRoadmap">#</a></span></h2>

<p>Along with general maintenance and my constant pursuit of optimization, I still want to get these things done in the future. I have carried most of these tasks over each month since I started this series, but plan to begin work on at least the first two soon.</p>

<h3 class="headers" id="ReleaseMarkdownParser">Release Markdown Parser<span>&nbsp;<a href="#ReleaseMarkdownParser">#</a></span></h3>

<p>I want to release my Markdown parser as its own project. I fixed a few bugs during the rewrite, but I still have some others to work out. At the least, I want to go public with greater coverage of the spec, and with the ability to handle multi-line strings and entire files at once. My true goal is to design a performant Markdown parser and then write an efficient implementation of it. <a href="https://talk.commonmark.org/t/performance-of-commonmark-reference-implementations/16">Several people</a> have already done some interesting work in this space. At present, it implements the subset of the spec I use on a regular basis, and handles files one line at a time.</p>

<h3 class="headers" id="PublishImplementationofMarkdownSpec">Publish Implementation of Markdown Spec<span>&nbsp;<a href="#PublishImplementationofMarkdownSpec">#</a></span></h3>

<p>Along with the release of my Markdown parser, I will need to outline the peculiarities of my implementation. Parity with <a href="https://daringfireball.net/projects/markdown/">John Gruber&#8217;s</a> spec would make sense, or something like <a href="https://github.github.com/gfm/">GitHub Flavored Markdown</a> which has much more detailed documentation, so I may go this route; if not, I will need to produce my own documentation. This would cover weird edge cases for the most part, but it would also give those who use my engine have some sort of explanation for why their article looks weird. In brief, my argument against going with a standard comes down to the fact that I have little use for most of those features and edge use cases. Once this becomes its own project, though, that others may use, this argument gets even shakier. I will have to spend some time thinking about this before I move forward.</p>

<h3 class="headers" id="ImproveDocumentation">Improve Documentation<span>&nbsp;<a href="#ImproveDocumentation">#</a></span></h3>

<p>A few of the ways I think I can improve the README in particular:</p>

<ul>
<li>Re-create usage GIFs. I had a few neat GIFs that showed off First Crack&#8217;s simple install process and easy use case, but I will have to re-create those after the rewrite.</li>
<li>Performance graphs of First Crack&#8217;s back-end performance versus other, similar engines. At less than two seconds to build a website of over one thousand pages, I want to highlight this.</li>
<li>Performance graphs of the web pages First Crack builds versus the pages common content management systems build.</li>
<li>Screenshots. This site is a live demo of the engine, but I like the idea of having a few pictures in there, too.</li>
</ul>

<p>As always, I look forward to the work ahead.</p>


<p><a class='read_more_link' href='/blog/first-crack-release-notes-0220.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://spacetime.dev/plausibly-deniable-encryption">plausibly deniable encryption</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-27 07:11:30-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/27 07:11:30 EST</time>
<p>A fascinating read, especially as someone who investigates and architects secure systems for a living. See also, <a href="https://spacetime.dev/encrypting-secrets-in-memory"><em>encrypting secrets in memory</em></a>.</p>


<p><a class='read_more_link' href='/blog/plausibly-deniable-encryption.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://wiki.alopex.li/LetsBeRealAboutDependencies">Let's be Real About Dependencies</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-26 06:54:42-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/26 06:54:42 EST</time>
<p>I <a href="/projects.html#firstCrack">don&#8217;t like</a> <a href="https://zacs.site/blog/linear-python.html">dependencies</a>, but excusing one language&#8217;s reliance on bucketloads of them because others use built-in libraries misses the point. I care about the number of dependencies I have to install just for your project. On a system full of libraries that could have met most of those requirements, as evidenced by other, similar projects that do not need hundreds of extra packages, the fact that yours does gives me pause. The fact that this language seems to cause this leads me to believe some fundamental shortcoming must exist. Let&#8217;s not excuse that.</p>


<p><a class='read_more_link' href='/blog/lets-be-real-about-dependencies.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://kk.org/thetechnium/amish-hackers-a/">Amish Ingenuity</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-25 07:14:34-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/25 07:14:34 EST</time>
<p><a href="https://zacs.site/blog/100-true-fans.html">Speaking of Kevin Kelly</a>, he wrote an interesting article examining the Amish&#8217;s relationship with technology.</p>

<blockquote>
<p>&#8220;They don&#8217;t adopt everything new but what new technology they do embrace, they take up about half a century after everyone else does. By that time, the benefits and costs are clear, the technology stable, and it is cheap.&#8221;</p>
</blockquote>

<p>Now that just seems like good sense.</p>


<p><a class='read_more_link' href='/blog/amish-hackers.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://sanderknape.com/2020/02/building-a-static-serverless-website-using-s3-cloudfront/">&#91;Don't build&#93; a static serverless website using S3 and CloudFront</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-24 07:29:06-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/24 07:29:06 EST</time>
<p>Sander will get you up and running, probably, but <a href="https://zacs.site/blog/dont-use-amazon-web-services.html">don&#8217;t use Amazon Web Services</a>. <a href="https://zacs.site/blog/own-your-platform.html">Have a website</a>, but <a href="https://zacs.site/blog/how-to-own-your-platform.html">use the much more user friendly Google Firebase to host it for free</a>.</p>


<p><a class='read_more_link' href='/blog/dont-build-using-aws.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://a16z.com/2020/02/06/100-true-fans/">1,000 True Fans? Try 100</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-21 16:45:08-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/21 16:45:08 EST</time>
<p>Over a decade ago, <a href="https://kk.org/thetechnium/1000-true-fans/">Keven Kelly put forward the idea that creators could earn a living from 1,000 fans</a>. In <a href="https://a16z.com/2020/02/06/100-true-fans/">this piece</a>, Li Jin proposes that they can do the same from 100 super fans. Crucially, though, as the number of patrons goes down, the value that creator provides must go up. Many seem to forget this last point, and see headlines like these as evidence that they can somehow make it with 1,000 subscribers or 100 readers. It just doesn&#8217;t work. Understand the tradeoffs, make a realistic plan, and never <a href="https://zacs.site/blog/simple-not-easy.html">quit</a>.</p>


<p><a class='read_more_link' href='/blog/100-true-fans.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://utf9k.net/blog/publish-old-works/">You should publish your older works</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-20 08:02:09-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/20 08:02:09 EST</time>
<p>I read a few of Marcus&#8217;s posts, and liked <a href="https://utf9k.net/blog/25/">them</a> <a href="https://utf9k.net/blog/email-lookup/">all</a>, but it was <a href="https://utf9k.net/blog/publish-old-works/">his link</a> to <a href="https://youtu.be/X2wLP0izeJE">an interview with Ira Glass</a> that made me post this. Most have heard this many times before, but it bears repeating: doing good work means first doing a lot of bad work, and having the tenacity to get through those discouraging times. The great creators, to whom far too many aspiring creators prematurely compare themselves, made it through because they pressed on. Success is not a mystery, it&#8217;s just <a href="https://zacs.site/blog/simple-not-easy.html">hard</a>. Put in the work to get there.</p>


<p><a class='read_more_link' href='/blog/you-should-publish-your-older-works.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://techcrunch.com/2020/02/17/regulate-facebook/">Facebook asks for a moat of regulations it already meets</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-19 07:26:25-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/19 07:26:25 EST</time>
<p>Josh Constine, writing for TechCrunch:</p>

<blockquote>
<p>&#8220;It&#8217;s suspiciously convenient that Facebook already fulfills most of the regulatory requirements it&#8217;s asking governments to lay on the rest of the tech industry. ... We already saw this happen with GDPR. The idea was to strengthen privacy and weaken exploitative data collection that tech giants like Facebook and Google depend on for their business models. The result was that Facebook and Google actually gained or only slightly lost EU market share while all other adtech vendors got wrecked by the regulation, according to WhoTracksMe.&#8221;</p>
</blockquote>

<p>Suspicious, no; convenient, yes; par for the course&#160;&#8212;&#160;also yes. What a surprise.</p>


<p><a class='read_more_link' href='/blog/facebook-moat.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/holiday-fitness.html">Holiday Fitness</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-18 07:37:22-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/18 07:37:22 EST</time>
<p>I took two weeks off work around Christmas. I spent the first touring Arizona, and the second at my parents&#8217; farm in Ohio. After a 605lb deadlift PR in early December, I felt like a break from the gym. Plus, I did not workout for the three weeks I spent driving up the east coast in 2018. Gym access did not factor into this trip&#8217;s planning process either, and so over those fifteen days, I worked out three times. Today, I want to share some thoughts about fitness on the road.</p>

<h3 class="headers" id="TheWhy">The Why<span>&nbsp;<a href="#TheWhy">#</a></span></h3>

<p>First, the why. I used to say I got into weightlifting because cardio took too much upkeep. Skip a few runs and watch that mile time go up. It took much longer, I said, to see those kinds of losses in strength. <a href="https://www.active.com/running/articles/how-quickly-do-you-lose-running-fitness">Most</a> articles <a href="https://www.youbeauty.com/fitness/how-fast-do-you-lose-strength-skipping-weight-training/">agree</a>, but I have had doubts for a while now. My Arizona trip reinforced those doubts, and digging into <a href="https://journals.lww.com/acsm-msse/Fulltext/2001/08000/Muscular_characteristics_of_detraining_in_humans.9.aspx">actual</a> <a href="https://journals.lww.com/nsca-jscr/Abstract/1994/05000/Physiological_and_Biochemical_Consequences_of.9.aspx">research</a> confirmed them. From Inigo Mujika and Sabino Padilla, in their 2000 paper <a href="https://journals.lww.com/acsm-msse/Fulltext/2001/08000/Muscular_characteristics_of_detraining_in_humans.9.aspx"><em>Muscular characteristics of detraining in humans</em></a>:</p>

<p>&#8220;Strength performance in general is readily maintained for up to 4 wk of inactivity, but highly trained athletes&#8217; eccentric force and sport-specific power, and recently acquired isokinetic strength, may decline significantly.&#8221; <a href="https://journals.lww.com/acsm-msse/Fulltext/2001/08000/Muscular_characteristics_of_detraining_in_humans.9.aspx">Source</a>.</p>

<p>And from Randal Wilber and Robert Moffatt, in their 1994 paper <a href="https://journals.lww.com/nsca-jscr/Abstract/1994/05000/Physiological_and_Biochemical_Consequences_of.9.aspx"><em>Physiological and Biochemical Consequences of Detraining in Aerobically Training Individuals</em></a>:</p>

<p>&#8220;... highly conditioned individuals appear to retain some of the benefits derived from endurance training despite remaining inactive for as long as 12 weeks. ... Conversely, in previously sedentary, moderately trained persons, training related adaptations are completely reversed to pretraining levels after approximately 10 weeks of inactivity.&#8221; <a href="https://journals.lww.com/nsca-jscr/Abstract/1994/05000/Physiological_and_Biochemical_Consequences_of.9.aspx">Source</a>.</p>

<p>Not only had I gotten this backwards, I could expect to lose strength 2 to 3 times <em>faster</em> than conditioning. To make matters worse, I saw those losses even faster than Mujika and Padilla predicted. Based on my break in 2018, my brief <a href="https://zacs.site/blog/trading-strength-for-conditioning.html">return to conditioning</a> last year, and my most recent trip, I lose about 10 pounds across each lift per week of rest. If I trade weightlifting for cardio, instead of just taking time off, that number goes up to about 25 pounds across my bench press, deadlift, and squat. It then takes around 1.5x the rest period to recoup my losses: it took three weeks to get back to my pre-holiday levels. I can now begin preparing for new PRs. </p>

<p>In short, rest costs 10lb per week across the board, and then I have to spend almost twice that long recouping my losses. If this does not make a compelling case for some sort of workout regimen even while traveling, nothing will. </p>

<h3 class="headers" id="TheHow">The How<span>&nbsp;<a href="#TheHow">#</a></span></h3>

<p>The need for a travel fitness plan became clear after my last trip, and it would have taken little to make it happen. On day one, I could have gone anywhere on my way out of Phoenix. Even Sedona and Flagstaff, mid-size towns in the mountains, had gyms. I would have had to go without at the Grand Canyon, but I could have tolerated a CrossFit gym in Page the next day before going back to Flagstaff, Sedona, and then Phoenix. Would this have taken away from the trip? If I thought of 8 A.M. wake-ups after watching Slay Bells on Lifetime until midnight a crucial part of the Arizona experience, yes&#160;&#8212;&#160;but I don&#8217;t, so no. I should have made better use of those hours. Would it have cost a lot? Maybe. Should I have done it anyway? Yes; will I next time? Yes again.</p>

<br />

<p>As I look back on this trip to Arizona, and start to think about the next adventure, I have decided to make gym access a real planning consideration. Weightlifting has become <a href="https://zacs.site/blog/my-road-to-weightlifting.html">a big part of my life</a>. At home, I like to say it is the hill I choose to die on: the one thing I will always do, no matter what happens. As I set my sights on the Canadian backwoods next, I may not have the luxury of such rigidity&#160;&#8212;&#160;but from now on, if not the hill I die on, I will at least defend it.</p>


<p><a class='read_more_link' href='/blog/holiday-fitness.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://zenhabits.net/honest-mindfulness/">The Honest Guide to Meditation</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-14 09:13:50-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/14 09:13:50 EST</time>
<p>I like most of Leo Babauta&#8217;s work, but this one disappointed me. He titled it <a href="https://zenhabits.net/honest-mindfulness/"><em>The Honest Guide to Mindfulness</em></a>, but a more apt title would have been <em>The Honest Guide to Meditation</em>&#160;&#8212;&#160;because he talked about nothing else. Meditation, though, is a practice some have used to become more mindful, not the goal itself, and by no means the epitome of mindfulness. </p>

<p>My favorite explanation of mindfulness came from an episode of <a href="https://5by5.tv/b2w">Back to Work</a>, in which Merlin Mann described it as the ability to watch cars go by without feeling the need to jump in. The patent absurdity of this analogy made the value of mindfulness value clear, when he explained that the cars symbolized our emotions: temporary, quick to change, and far too often dictated by people and situations over which we have no control. The goal of mindfulness&#160;&#8212;&#160;which, again, some have found <em>through</em> meditation&#160;&#8212;&#160;is not to do the impossible, to wrestle back from a chaotic world command over those cars, but rather to regain control of the one actor in that scenario you have any hope of influencing: yourself. </p>

<p>You will never control which cars come, when they go by, or who drives them, but you can&#160;&#8212;&#160;with practice&#160;&#8212;&#160;learn to control their ability to hijack your life. An honest guide to that, real mindfulness, may have done some good.</p>


<p><a class='read_more_link' href='/blog/the-honest-guide-to-meditation.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://arstechnica.com/science/2020/02/someone-used-neural-networks-to-upscale-a-famous-1896-video-to-4k-quality/">Denis Shiryaev used neural networks to upscale a famous 1896 video to 4k quality</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-12 17:05:13-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/12 17:05:13 EST</time>
<p>This is such a cool idea: Denis Shiryaev used Gigapixel AI&#8217;s neural network to upscale a classif video from 1896 into 4k; as Timothy Bee <a href="https://arstechnica.com/science/2020/02/someone-used-neural-networks-to-upscale-a-famous-1896-video-to-4k-quality/">points out</a>, a similar approach could then add color.  </p>

<p>One of my long-term projects involves making the small part of the internet I use every day available offline. As I <a href="/projects.html#lmtvRV">lean</a> toward a more nomadic lifestyle, I may not always have ready access to the familiar shows I stream on Netflix, for example, or that one news article from a few weeks ago. A single hard drive could store everything I have ever watched, read, and listened to, though, and so I want to make that happen. This goes well with one of my other long-term projects, which involves curating evergreen digital media for posterity&#8217;s sake. Think of the former as every movie I have ever watched, and the latter as the classics I want to save for my kids. There are many <a href="https://ukiahsmith.com/blog/which-compression-format-to-use-for-archiving/">subltle challenges</a> to this, but none so obvious as the fact that even video from a few years ago looks bad on modern displays. <a href="https://arstechnica.com/science/2020/02/someone-used-neural-networks-to-upscale-a-famous-1896-video-to-4k-quality/">Denis&#8217;s demonstration</a> gives me hope that this may not always be the case.</p>


<p><a class='read_more_link' href='/blog/1896-to-4k.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/lightning-round-10feb20.html">Lightning Round</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-10 11:42:26-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/10 11:42:26 EST</time>
<p>In <a href="https://zacs.site/blog/lightning-round-04dec19.html">the last lightning round</a>, I promised that these posts would give me somewhere to share things that used to slip through the cracks. Today I have two.</p>

<ul>
<li><a href="https://www.politico.com/news/magazine/2020/02/06/rachel-bitecofer-profile-election-forecasting-new-theory-108944">There Is No Swing Voter</a>. I would submit a hybrid theory: voter turnout chooses the party, and voter opinion chooses the candidate. </li>
<li><a href="https://www.theatlantic.com/magazine/archive/2020/03/the-2020-disinformation-war/605530/">The Billion-Dollar Disinformation Campaign to Reelect the President</a>. This writeup on some of the infrastructure and tactics behind the reelection campaign was fascinating.</li>

</ul>

<p><a class='read_more_link' href='/blog/lightning-round-10feb20.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">Command-line Tools can be 235x Faster than your Hadoop Cluster</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-02-04 18:45:52-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-02.html">02</a>/04 18:45:52 EST</time>
<p>I love stories like <a href="https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">Adam&#8217;s</a>. Too many people propose complex solutions to simple problems because they get excited about building something cool, and lose sight of their actual purpose: building a useful tool. I see this all the time at work. In this case, another developer used a Big Data approach for a Small Data problem, and Adam shows how a much simpler&#160;&#8212;&#160;but less cool(?)&#160;&#8212;&#160;one would have got it done much, much faster. Had this other developer <a href="https://zacs.site/blog/good-times-create-weak-men.html">understood the underlying technologies</a>, and taken some time for <a href="https://zacs.site/blog/linear-python.html">premature optimization</a>, he might have gotten there himself.</p>


<p><a class='read_more_link' href='/blog/235x-faster.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/linear-python.html">Sequential Exeuction, Multiprocessing, and Multithreading IO-Bound Tasks in Python</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-25 12:40:21-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/25 12:40:21 EST</time>
<html>
<style type="text/css">

.highlight .c{color:#408080;font-style:italic}.highlight .k{color:green;font-weight:700}.highlight .o{color:#666}.highlight .c1{color:#408080;font-style:italic}.highlight .go{color:#888}.highlight .gt{color:#04d}.highlight .kn{color:green;font-weight:700}.highlight .m{color:#666}.highlight .s{color:#ba2121}.highlight .nb{color:green}.highlight .no{color:#800}.highlight .ne{color:#d2413a;font-weight:700}.highlight .nf{color:#00f}.highlight .nn{color:#00f;font-weight:700}.highlight .nv{color:#19177c}.highlight .ow{color:#a2f;font-weight:700}.highlight .mi{color:#666}.highlight .s2{color:#ba2121}.highlight .s1{color:#ba2121}.highlight .bp{color:green}.highlight *{line-height:100%}

table{margin:0 auto;margin-bottom:2em;border-collapse:collapse;border:none !important;}table,td,th,tr{border:.1em solid #000;padding:.5em}td:hover{background-color:#cfcfcf}

/* Media Queries */

@media only screen and (min-device-width: 375px) and (max-device-width: 812px) and (-webkit-min-device-pixel-ratio: 3) {

table{display:inline-block;max-width: 90%;overflow:scroll}

}

</style>



<p>Python <a href="https://realpython.com/python-concurrency/">makes concurrency easy</a>. It took less than an hour to <a href="https://zacs.site/blog/first-crack-release-notes-0819.html">add multiprocessing to my blog engine</a>, <a href="/projects.html/firstCrack">First Crack</a>, and I have used it often since. Everyone likes to call premature optimization the root of all evil, but architecting programs for concurrent execution from the start has saved me hundreds of hours in large data capture and processing projects. Color me a Knuth skeptic. This article compares sequential execution, multiprocessing, and multithreading for IO-Bound tasks in Python, with simple code samples along the way.</p>



<h3 class="headers" id="Terms">Terms<span>&nbsp;<a href="#Terms">#</a></span></h3>



<p>First, terms. Most programs work from top to bottom. The next line runs after the last one finishes. We call these <strong>sequential</strong>. Adding <strong>multiprocessing</strong> to First Crack let the script use multiple cores to run multiple lines at the same time. Where the engine used to open a file, read its contents, close it, and then repeat those steps a thousand more times, it could now handle eight at once. <strong>Multithreading</strong> lives somewhere in the middle. These programs use a single core, but the processor forces small blocks&#160;&#8212;&#160;threads&#160;&#8212;&#160;to take turns. By pausing a block waiting to read a file so that another can make a network connection before coming back to the first, multithreading boosts efficiency and lowers runtime. The latter approaches are examples of <strong>concurrency</strong>, which&#160;&#8212;&#160;to make things easy&#160;&#8212;&#160;you can just think of as anything <em>not</em> sequential.</p>



<p>The rest of this article starts with a simple sequential script, after the section below, before moving on to much faster concurrent versions later. Each section also includes runtime analysis, so you can see just how big an impact concurrency can have.</p>



<h3 class="headers" id="Imports">Imports<span>&nbsp;<a href="#Imports">#</a></span></h3>



<p>I excluded the import statements from the code in the following sections, for brevity&#8217;s sake. For those who want to follow along at home, make sure your script starts with these lines:</p>



<div class="highlight"><pre><span></span><span class="c1"># Imports</span>

<span class="kn">from</span> <span class="nn">sys</span> <span class="kn">import</span> <span class="n">argv</span> <span class="c1"># Capture command line parameters</span>

<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span> <span class="k">as</span> <span class="n">CorePool</span> <span class="c1"># Multiprocessing</span>

<span class="kn">from</span> <span class="nn">multiprocessing.pool</span> <span class="kn">import</span> <span class="n">ThreadPool</span> <span class="c1"># Multithreading</span>

<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span> <span class="c1"># Sleep</span>

<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span> <span class="c1"># Rounding</span>

<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span> <span class="c1"># Execution time</span>

</pre></div>



<p>I will not use most of these functions for a while, but use all of them in time. If you do decide to follow along at home, you will need Python 3.7 or later.</p>



<h3 class="headers" id="SequentialExecution">Sequential Execution<span>&nbsp;<a href="#SequentialExecution">#</a></span></h3>



<p>The first&#160;&#8212;&#160;and most common&#160;&#8212;&#160;approach to concurrency is to avoid it. Consider this simple script:</p>



<div class="highlight"><pre>

<span class="c1"># Method: handle</span>

<span class="c1"># Purpose: Handle item.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - item: Item to handle (X)</span>

<span class="c1"># Return: 0 - Success, 1 - Fail (Int)</span>

<span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>

<span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="k">return</span> <span class="mi">1</span> <span class="c1"># Success</span>



<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>



<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>

<span class="n">handle</span><span class="p">(</span><span class="n">each</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Sequential time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>

</pre></div>



<p>The generic method <code>handle</code> does nothing&#160;&#8212;&#160;but by sleeping for two seconds, it simulates a long IO-bound task. I chose to simulate this type of task&#160;&#8212;&#160;as opposed to a CPU-bound one&#160;&#8212;&#160;because most of my recent projects have involved downloading and reading massive files. These types of jobs spend most of their time waiting on data from the network or an external hard drive, which requires little from the processor. In a real project, I might replace <code>sleep(2)</code> with code to download a web page, parse the HTML, and write to a file. For consistency across runs, I just use <code>sleep</code> here. <code>x = range(100)</code> creates a list from 0 to 99, and the <code>for</code> loop then calls <code>handle</code> one hundred times, once for each number. </p>



<p>We can model best-case runtime with the formula <code>T = h &#42; n + o</code>, with <code>T</code> as total execution time, <code>h</code> as the amount of time <code>handle</code> takes to run, <code>n</code> as the number of times the method runs, and <code>o</code> as the overhead to initialize, operate, and exit the script. The script above should take just over 200 seconds to finish: <code>T = 2 &#42; 100 + o = 200 + o</code></p>



<p>The script ran for 200.17 seconds, which makes <code>o</code>&#160;&#8212;&#160;the overhead to initialize, operate, and exit the script, in seconds&#160;&#8212;&#160;equal to 0.17. Next, let&#8217;s add multiprocessing and see what changes.</p>



<h3 class="headers" id="Multiprocessing">Multiprocessing<span>&nbsp;<a href="#Multiprocessing">#</a></span></h3>



<p>Consider the script below. <code>handle</code> remains unchanged. <code>x = range(100)</code> creates the same one hundred-item list from 0 to 99, but then <code>Core_Orchestrator</code> calls <code>handle</code> for each number 0 to 99. </p>



<div class="highlight"><pre>

<span class="c1"># Method: handle</span>

<span class="c1"># Purpose: Handle item.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - item: Item to handle (X)</span>

<span class="c1"># Return: 0 - Success, 1 - Fail (Int)</span>

<span class="k">def</span> <span class="nf">handle</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>

<span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="k">return</span> <span class="mi">1</span> <span class="c1"># Success</span>



<span class="c1"># Method: Core_Orchestrator</span>

<span class="c1"># Purpose: Facilitate multiprocessing.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - input_list: List to farm out to cores (List)</span>

<span class="c1"># Return: True, All successful; False, At least one fail (Bool)</span>

<span class="k">def</span> <span class="nf">Core_Orchestrator</span><span class="p">(</span><span class="n">input_list</span><span class="p">):</span>

<span class="n">pool</span> <span class="o">=</span> <span class="n">CorePool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">MAX_CORES</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">input_list</span><span class="p">)</span>

<span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">del</span> <span class="n">pool</span>

<span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>



<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>



<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">Core_Orchestrator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Multiprocessing time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>

</pre></div>



<p>Recall that multiprocessing lets the script use multiple cores to run multiple lines at the same time. My computer has eight cores, so <code>Core_Orchestrator</code> runs eight instances of <code>handle</code> at once. We can now model execution time with <code>T = (h &#42; n)/c + n/c&#42;y + o</code>. </p>



<p>Let me break this new formula down: we can represent the time to run <code>handle</code> <code>n</code> times with <code>(h &#42; n)</code>. <code>(h &#42; n)/c</code>, then, becomes the time to run <code>handle</code> <code>n</code> times on <code>c</code> cores. Multiple cores introduce some overhead, though, which we can account for with <code>n/c&#42;y</code>: the number of times the script will have to assign <code>handle</code> to a new core, <code>n/c</code>, times the unknown amount of time that takes, <code>y</code>. <code>o</code> is, again, the overhead to initialize, operate, and exit the script.</p>



<p>Assuming <code>o</code> remains constant, our new formula says we can expect the code above to take at least 25 seconds: <code>T = (2 &#42; 100)/8 + 100/8&#42;y + 0.17 = 25.17 + 12.5y</code>. Since we don&#8217;t have a value for <code>y</code>, though, we cannot say how far over. Let&#8217;s find out.</p>



<p>The script finishes in <strong>0:00:32.09</strong>, which gives us a value of 0.55 for <code>y</code>. At this point, we have two extremes by which to judge performance: the sequential approach took 200.17 seconds, while the multiprocessor approach took 32.09 seconds. Let&#8217;s see if we can beat it with multithreading, next.</p>



<h3 class="headers" id="Multithreading">Multithreading<span>&nbsp;<a href="#Multithreading">#</a></span></h3>



<p>In the script below, <code>handle</code> once again remains unchanged, <code>x = range(100)</code> creates the same one hundred-item list from 0 to 99, but then <code>Thread_Orchestrator</code> calls <code>handle</code> for each number 0 to 99. <code>Thread_Orchestrator</code> uses a max of eight threads. </p>



<p>Will this script match the performance of the sequential one, with <code>T = h &#42; n + o</code>? It runs on a single core, after all. Or will it look more like the multiprocessed code, with execution time measured by <code>T = (h &#42; n)/c + n/c&#42;y + o</code>?</p>



<div class="highlight"><pre>

<span class="c1"># Method: Thread_Orchestrator</span>

<span class="c1"># Purpose: Facilitate multithreading.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - input_list: List to farm out to threads (List)</span>

<span class="c1"># Return: True, All successful; False, At least one fail (Bool)</span>

<span class="k">def</span> <span class="nf">Thread_Orchestrator</span><span class="p">(</span><span class="n">in_list</span><span class="p">):</span>

<span class="k">try</span><span class="p">:</span>

<span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPool</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">thread_pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">in_list</span><span class="p">)</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">del</span> <span class="n">thread_pool</span>

<span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

<span class="c1"># print(e)</span>

<span class="k">return</span> <span class="bp">False</span>



<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>



<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">Thread_Orchestrator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Multithreading time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>

</pre></div>



<p>This script finished in <strong>32.08</strong> seconds. Whether eight cores sleep for two seconds or a single core waits for eight threads to sleep for two seconds apiece, the same amount of time passes. As a result, the non-parallel multithreaded approach managed to match the parallel multiprocessing one. In general, the execution time for these two approaches will match for IO-bound tasks; it will not for CPU-bound tasks, though. If I had used a complex math operation that required many CPU cycles, the multiprocessing method would have split the work across eight cores, while a single one would have had to do all the work for each thread in the multithreaded code. The table below explains when to use these strategies.</p>



<table>

<tr>

<td>Bottleneck</td><td>Example</td><td>Optimize with</td>

</tr>

<tr>

<td>IO</td><td>Network connection, file operation</td><td>Multithreading</td>

</tr>

<tr>

<td>CPU</td><td> Complex math problem, search</td><td>Multiprocessing</td>

</tr>

</table>



<p>Given the simulated IO-bound task here, if the multiprocessing version ran just as fast as the multithreaded one, why bother with multithreading at all? Because the max number of cores a processor has is a hard physical limit, while the max number of threads is a logical one. I can never use more than eight cores, but I can use as many threads as my operating system will allow. In practice, I have found that limit hovers around 1,000 per process. </p>



<p>To answer my question from earlier, we can model multithreaded performance like we did multiprocessing<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>, with <code>T = (h &#42; n)/t + n/t&#42;z + o</code>&#160;&#8212;&#160;except with <code>t</code> as the number of threads used, and <code>z</code> as the overhead of assigning <code>handle</code> to a new thread. Using the execution time <code>T</code> of the last run, 32.08 seconds, we now have a value for <code>z</code>: 0.55. This formula also tells us that we can minimize <code>T</code> by increasing <code>t</code> toward its limit around 1,000. Let&#8217;s test this theory.</p>



<p>The script below uses 16 threads (<code>t=16</code>). According to our formula and assuming <code>o</code> and <code>z</code> remain constant, it should finish in about 16 seconds: <code>T = 200/16 + 100/16(0.55) + 0.17 = 16.11</code></p>



<div class="highlight"><pre>

<span class="c1"># Method: Thread_Orchestrator</span>

<span class="c1"># Purpose: Facilitate multithreading.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - input_list: List to farm out to threads (List)</span>

<span class="c1"># Return: True, All successful; False, At least one fail (Bool)</span>

<span class="k">def</span> <span class="nf">Thread_Orchestrator</span><span class="p">(</span><span class="n">in_list</span><span class="p">):</span>

<span class="k">try</span><span class="p">:</span>

<span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPool</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">thread_pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">in_list</span><span class="p">)</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">del</span> <span class="n">thread_pool</span>

<span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

<span class="c1"># print(e)</span>

<span class="k">return</span> <span class="bp">False</span>



<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>



<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="n">Thread_Orchestrator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Multithreading time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>

</pre></div>



<p>The script finished in <strong>16.07</strong> seconds with 16 threads, and <strong>2.15</strong> seconds with 100. More threads over 100 could not make this faster, though, because the script only had 100 tasks to complete; more would just go unused. Is this the best we can do? No: if the multiprocessing code ran on a machine with 100 cores, each core would run <code>handle</code> once and all cores would run their instance at the same time; execution would take about 2 seconds, since <code>handle</code> takes 2 seconds. Are 2.15 seconds <em>realistically</em> the best we can do, though? Maybe; I don&#8217;t have a 100 core machine laying around&#160;&#8212;&#160;but perhaps we can get closer, by combining multiprocessing and multithreading.</p>



<h3 class="headers" id="MultiprocessingMultithreading">Multiprocessing + Multithreading: The Blended Approach<span>&nbsp;<a href="#MultiprocessingMultithreading">#</a></span></h3>



<p>Getting multithreading and multiprocessing to work together took some work. I&#8217;ll walk you through the code first, then delve into the results. </p>



<div class="highlight"><pre>

<span class="c1"># Global control variables</span>

<span class="c1"># MAX_CORES: Maximum number of cores</span>

<span class="n">MAX_CORES</span> <span class="o">=</span> <span class="mi">8</span>

</pre></div>



<p><code>multiprocessing.Pool()</code> creates a handle through which the script delegates tasks to individual cores. This command uses <code>multiprocessing.cpu_count()</code> to define the number of available cores in the pool. In the virtual environment I wrote most of this article in, though, that function gave me incorrect results. Creating a variable <code>MAX_PROCESSORS</code> and then overriding <code>multiprocessing.cpu_count()</code> with it when instantiating the pool fixed the problem. Your mileage may vary.</p>



<div class="highlight"><pre>

<span class="c1"># Method: Core_to_Thread_Orchestrator</span>

<span class="c1"># Purpose: Facilitate multiprocessing and multithreading.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - input_list: List to farm out to threads by core (List)</span>

<span class="c1"># Return: True, All successful; False, At least one fail (Bool)</span>

<span class="k">def</span> <span class="nf">Core_to_Thread_Orchestrator</span><span class="p">(</span><span class="n">input_list</span><span class="p">):</span>

<span class="k">try</span><span class="p">:</span>

<span class="n">pool</span> <span class="o">=</span> <span class="n">CorePool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="n">MAX_CORES</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="n">MAX_CORES</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Thread_Orchestrator</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">input_list</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">n</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_list</span><span class="p">),</span> <span class="n">n</span><span class="p">)])</span>

<span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">del</span> <span class="n">pool</span><span class="p">,</span> <span class="n">n</span>

<span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

<span class="c1"># print(e)</span>

<span class="k">return</span> <span class="bp">False</span>

</pre></div>



<p><code>Core_to_Thread_Orchestrator</code> accepts an input list, conveniently named <code>input_list</code>, then creates a pool of cores. The line, <code>results = pool.map(Thread_Orchestrator, [list(input_list[i:i+n]) for i in range(0, len(input_list), n)])</code>, needs some extra explaining.</p>



<ol>

<li><strong>Divide <code>input_list</code> into even sub-lists for each core.</strong> <code>n = ceil(len(x)/MAX_CORES)</code> uses <code>ceil</code> to make sure a list of 100 elements on an 8 core machine does not get split into 8 sub-lists with 12 elements each (<code>int(100/8=12.5)=12</code>). This would only account for 96 elements and orphan the last 4. For cases like this, <code>ceil</code> ensures 8 sub-lists are created with 13 elements each, where the last one has just 9. <code>[list(input_list[i:i+n]) for i in range(0, len(input_list), n)]</code> then splits <code>input_list</code> into even sub_lists such that each core will have about the same amount of work to do.</li>

<li> <strong>Multithread the processing of each sub-list.</strong> <code>pool.map</code> hands each sub-list off to a different core&#8217;s multithreading function. This has two major benefits. First, this allows each core to supervise the multithreading of a fraction of <code>input_list</code>, rather than the entire thing. The system then has to create fewer threads per core, which means each core can spend less time pausing and resuming threads. In theory, this approach also multiplies the max number of possible threads: where one core might have tapped out at 1,000, 8 cores should manage 8,000 without issue. In practice, though, most systems limit thread count by process rather than by core; on my system, that limit hovers around 1,000.</li>

<li> <strong>Capture success or failure for all cores.</strong> <code>result</code> becomes a list with a return value for each core.</li>

</ol>

<p><code>return all(result)</code> returns True if all processes succeeded, but False if <em>any</em> failed. </p>



<div class="highlight"><pre>

<span class="c1"># Method: Thread_Orchestrator</span>

<span class="c1"># Purpose: Facilitate multithreading.</span>

<span class="c1"># Parameters:</span>

<span class="c1"># - input_list: List to farm out to threads (List)</span>

<span class="c1"># Return: True, All successful; False, At least one fail (Bool)</span>

<span class="k">def</span> <span class="nf">Thread_Orchestrator</span><span class="p">(</span><span class="n">in_list</span><span class="p">):</span>

<span class="k">try</span><span class="p">:</span>

<span class="n">thread_pool</span> <span class="o">=</span> <span class="n">ThreadPool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">in_list</span><span class="p">))</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">thread_pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">in_list</span><span class="p">)</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">thread_pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>

<span class="k">del</span> <span class="n">thread_pool</span>

<span class="k">return</span> <span class="nb">all</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>

<span class="c1"># print(e)</span>

<span class="k">return</span> <span class="bp">False</span>

</pre></div>



<p>As we saw earlier, multithreading handles IO-bound tasks best with a thread for each task. Since <code>Thread_Orchestrator</code> now receives a variable number of tasks, it now calculates the appropriate number of threads to create with <code>len(in_list)</code>. Again, using more threads than tasks would not improve runtime. <code>results = thread_pool.map(handle, in_list)</code> then assigns <code>handle</code> to a thread for each element in the input list, captures the results in an array just like the previous method, and returns True of all threads succeed. If any fail, <code>Thread_Orchestrator</code> returns False. </p>



<div class="highlight"><pre>

<span class="c1"># Read number of items to generate test data set with from parameter.</span>

<span class="c1"># Default to 100.</span>

<span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">argv</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">100</span>

<span class="k">else</span><span class="p">:</span>

<span class="n">seed</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>



<span class="c1"># Expand the range to a list of values</span>

<span class="c1"># seed = 100 -&gt; 100 element list</span>

<span class="c1"># seed = 500 -&gt; 500 element list</span>

<span class="n">x</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>



<span class="c1"># Print seed and results</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Seed: {seed}&quot;</span><span class="p">)</span>



<span class="c1"># # Multiprocess</span>

<span class="c1"># t1 = datetime.now()</span>

<span class="c1"># if (Core_Orchestrator(x) == False):</span>

<span class="c1">#     print(&quot;-- Core orchestrator failed.&quot;)</span>

<span class="c1"># else:</span>

<span class="c1">#     t2 = datetime.now()</span>

<span class="c1">#     print(&quot;Multiprocessing time: {}&quot;.format((t2-t1).total_seconds()))</span>



<span class="c1"># Multithreading</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">if</span> <span class="p">(</span><span class="n">Thread_Orchestrator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="bp">False</span><span class="p">):</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;-- Thread orchestrator failed.&quot;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;-- Multithreading time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>



<span class="c1"># Multiprocessing + multithreading</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">if</span> <span class="p">(</span><span class="n">Core_to_Thread_Orchestrator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="o">==</span> <span class="bp">False</span><span class="p">):</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;-- Processor to thread orchestrator failed.&quot;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;-- Multiprocessing and multithreading time: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">t2</span><span class="o">-</span><span class="n">t1</span><span class="p">)</span><span class="o">.</span><span class="n">total_seconds</span><span class="p">()))</span>

</pre></div>



<p>The code above accepts a parameter for the number of times <code>handle</code> must run, and then records the runtime for the multithreaded method and the blended method. Even if one fails, the test continues. The snippet below tests the limits of both approaches by feeding the script values from 100 to 1,000 in increments of 100. It does this ten times, to lessen the impact of anomalous runs.</p>



<div class="highlight"><pre><span></span><span class="k">for</span> k in <span class="o">{</span><span class="m">1</span>..10<span class="o">}</span><span class="p">;</span> <span class="k">do</span> <span class="k">for</span> i in <span class="o">{</span><span class="m">100</span>..1000..100<span class="o">}</span><span class="p">;</span> <span class="k">do</span> python3 main.py <span class="nv">$i</span> &gt;&gt; <span class="nv">$k</span><span class="s2">&quot;.txt&quot;</span><span class="p">;</span> <span class="nb">kill</span> <span class="k">$(</span>ps aux <span class="p">|</span> grep python <span class="p">|</span> awk <spanclass="s1">&#39;{print $2}&#39;</span><span class="k">)</span> <span class="m">2</span>&gt;/dev/null<span class="p">;</span> <span class="k">done</span><span class="p">; <span class="k">done</span><span class="p">

</pre></div>



<p>I could have done this all in Python, but this approach does a few things for me. For one, it forces the script to initialize, execute, and exit for each set of tasks from 100 to 1,000. This lessens the chance of cache or memory usage impacting successive runs. <code>kill $(ps aux | grep python | awk &#8216;{print $2}&#8217;) 2&gt; /dev/null</code> makes sure no Python processes stick around to interfere with those runs. Again, it also goes through this process ten times, to lessen the impact of anomalous runs. Together, these help give me as unbiased a picture of the script&#8217;s runtime as possible. Check out the results, tabled below:</p>



<table>

<tr>

<td>Approach</td><td> Tasks </td><td>Run 1</td><td>Run 2</td><td>Run 3</td><td>Run 4</td><td>Run 5</td><td>Run 6</td><td>Run 7</td><td>Run 8</td><td>Run 9</td><td>Run 10</td><td>AVG</td>

</tr>

<tr>

<td>Blended</td><td>100</td><td> 3.567204 </td><td>2.48169 </td><td> 2.469574 </td><td> 2.571985 </td><td> 2.495898 </td><td> 2.509916 </td><td> 2.487354 </td><td> 2.551873 </td><td> 2.520211 </td><td> 2.494282 </td><td> 2.6149987 </td>

</tr>

<tr>

<td>Blended</td><td>200</td><td>2.62477 </td><td> 2.721776 </td><td> 2.623119 </td><td>2.62792 </td><td> 2.666248 </td><td>2.65166 </td><td> 2.656948 </td><td> 2.607229 </td><td> 2.581664 </td><td> 2.617885 </td><td> 2.6379219 </td>

</tr>

<tr>

<td>Blended</td><td>300</td><td> 3.084136 </td><td> 2.766728 </td><td> 2.820711 </td><td> 2.718879 </td><td>2.71363 </td><td> 2.730298 </td><td> 2.764282 </td><td> 2.694365 </td><td>2.71308 </td><td> 2.710206 </td><td> 2.7716315 </td>

</tr>

<tr>

<td>Blended</td><td>400</td><td> 3.834809 </td><td> 3.039956 </td><td> 3.025324 </td><td> 2.826441 </td><td> 2.831418 </td><td> 2.902106 </td><td> 2.811155 </td><td> 2.893164 </td><td> 2.824065 </td><td> 2.815037 </td><td> 2.9803475 </td>

</tr>

<tr>

<td>Blended</td><td>500</td><td> 3.412031 </td><td> 3.085576 </td><td> 3.107757 </td><td> 2.994405 </td><td> 2.970532 </td><td> 3.066721 </td><td> 2.962216 </td><td> 3.010268 </td><td> 2.919665 </td><td> 2.920715 </td><td> 3.0449886 </td>

</tr>

<tr>

<td>Blended</td><td>600</td><td> 3.920105 </td><td> 3.276128 </td><td>3.20756 </td><td> 3.191376 </td><td>3.24736 </td><td>3.18067 </td><td> 3.095356 </td><td> 3.182228 </td><td> 3.177074 </td><td>3.12045 </td><td> 3.2598307 </td>

</tr>

<tr>

<td>Blended</td><td>700</td><td> 3.893453 </td><td> 3.338353 </td><td>3.45412 </td><td> 3.307333 </td><td> 3.269286 </td><td> 3.375174 </td><td> 3.416062 </td><td> 3.189951 </td><td> 3.309285 </td><td> 3.223167 </td><td> 3.3776184 </td>

</tr>

<tr>

<td>Blended</td><td>800</td><td> 4.396074 </td><td> 3.409177 </td><td> 3.489747 </td><td> 3.441516 </td><td> 3.416976 </td><td>3.33599 </td><td> 3.333954 </td><td> 3.409126 </td><td> 3.298936 </td><td>3.52455 </td><td> 3.5056046 </td>

</tr>

<tr>

<td>Blended</td><td>900</td><td> 4.138501 </td><td> 3.736235 </td><td> 3.642134 </td><td> 3.608156 </td><td> 3.699388 </td><td> 3.624607 </td><td> 3.776716 </td><td> 3.607106 </td><td>3.60067 </td><td> 3.532703 </td><td> 3.6966216 </td>

</tr>

<tr>

<td> Multithreaded </td><td>100</td><td> 2.530468 </td><td> 2.678918 </td><td> 2.375514 </td><td> 2.669632 </td><td> 2.716273 </td><td> 2.433133 </td><td> 2.633597 </td><td> 2.528427 </td><td> 2.689116 </td><td> 2.529757 </td><td> 2.5784835 </td>

</tr>

<tr>

<td> Multithreaded </td><td>200</td><td> 2.646297 </td><td> 2.301428 </td><td> 2.220176 </td><td> 2.269561 </td><td>2.33174 </td><td> 2.266194 </td><td> 2.251354 </td><td> 2.290965 </td><td> 2.278389 </td><td> 2.307648 </td><td> 2.3163752 </td>

</tr>

<tr>

<td> Multithreaded </td><td>300</td><td> 2.516477 </td><td> 2.406957 </td><td> 2.401755 </td><td> 2.533726 </td><td> 2.390161 </td><td> 2.862111 </td><td>2.38876 </td><td> 2.384127 </td><td> 2.389991 </td><td> 2.398563 </td><td> 2.4672628 </td>

</tr>

<tr>

<td> Multithreaded </td><td>400</td><td> 2.482953 </td><td> 2.546255 </td><td> 2.676493 </td><td> 2.495154 </td><td>2.58571 </td><td> 2.522376 </td><td> 2.571323 </td><td> 2.506227 </td><td> 2.574394 </td><td> 2.468326 </td><td> 2.5429211 </td>

</tr>

<tr>

<td> Multithreaded </td><td>500</td><td> 3.363701 </td><td>2.85764 </td><td> 2.775013 </td><td> 2.604138 </td><td> 2.645682 </td><td> 2.601216 </td><td> 2.622577 </td><td> 2.702628 </td><td> 2.785129 </td><td> 2.667436 </td><td>2.762516 </td>

</tr>

<tr>

<td> Multithreaded </td><td>600</td><td> 2.987607 </td><td> 2.724781 </td><td> 2.882752 </td><td> 2.681507 </td><td> 2.788063 </td><td> 3.160047 </td><td> 2.780519 </td><td> 3.312241 </td><td> 3.519288 </td><td> 2.788334 </td><td> 2.9625139 </td>

</tr>

<tr>

<td> Multithreaded </td><td>700</td><td> 3.457589 </td><td> 3.197889 </td><td> 2.950593 </td><td>2.88573 </td><td> 2.986151 </td><td>2.9273</td><td> 2.890827 </td><td> 3.018946 </td><td> 2.894577 </td><td> 3.189955 </td><td> 3.0399557 </td>

</tr>

<tr>

<td> Multithreaded </td><td>800</td><td> 3.291344 </td><td> 3.208601 </td><td> 3.031519 </td><td> 2.981974 </td><td> 2.979717 </td><td> 6.996563 </td><td> 3.098343 </td><td> 3.908249 </td><td> 3.083194 </td><td> 7.007135 </td><td> 3.9586639 </td>

</tr>

<tr>

<td> Multithreaded </td><td>900</td><td> 3.532445 </td><td> 3.201465 </td><td> 3.164539 </td><td> 3.478344 </td><td> 5.107173 </td><td> 3.211502 </td><td> 3.120932 </td><td> 3.690724 </td><td> 3.577692 </td><td> 3.147345 </td><td> 3.5232161 </td>

</tr>

</table>



<p>The graph below visualizes execution time as a function of tasks, from 100 to 900. After 900, the system refused to spawn new threads; the dotted lines predict execution time beyond that point. <code>y = 0.0237x2 - 0.0655x + 2.4838</code> models the multithreading method with a R&sup2; value of 0.83, and <code>y = 0.0038x2 + 0.1019x + 2.4676</code> models the blended method with a R&sup2; value of 0.99.</p>



<div class='image'><img src='https://zacs.site/assets/images/Execution_time_as_a_function_of_tasks.png' alt='Execution time as a function of tasks' title='Execution time as a function of tasks' loading='lazy' /></div>



<p>The multithreaded method&#8217;s runtime consistently spikes with 800 tasks. Interestingly, normalizing the average runtime for 800 tasks to fall between 700&#8217;s and 900&#8217;s changes the trendline function from <code>y = 0.0237x2 - 0.0655x + 2.4838</code> to <code>y = 0.0185x2 - 0.0481x + 2.4838</code>, and causes the R&sup2; value to jump from 0.83 to 0.96. Check out that graph below.</p>



<div class='image'><img src='https://zacs.site/assets/images/Normalized_execution_time_as_a_function_of_tasks.png' alt='Normalized execution time as a function of tasks' title='Normalized execution time as a function of tasks' loading='lazy' /></div>



<h3 class="headers" id="ConclusionsandTakeaways">Conclusions and Takeaways<span>&nbsp;<a href="#ConclusionsandTakeaways">#</a></span></h3>



<p>To return to my question from earlier, are 2.15 seconds the best we can do? Recall that <code>Thread_Orchestrator</code> blew through 100 simulated IO-bound tasks in 2.15 seconds, using 100 threads. Over ten runs, it averaged 2.16 seconds; the blended multiprocessed + multithreaded method, on the other hand, averaged 2.44 seconds over 10 runs. To answer my question from earlier, then, 2.15 seconds are the best we can do. Multithreading wins for IO-bound tasks.</p>



<p>As the number of IO-bound tasks grows, that eventually changes. The multithreaded method&#8217;s execution time stays below the blended method&#8217;s from 100 to 900 tasks, but the former grows faster than the latter. On a system that permits a process to spawn more than 1,000 threads, the blended approach will begin to win out when processing over 1,000 IO-bound tasks. The table below summarizes when to use multithreading, multiprocessing, or a mix of both.</p>



<table>

<tr>

<td>Bottleneck </td><td> Example</td><td> Tasks</td><td> Optimize with</td>

</tr>

<tr>

<td>CPU</td><td> Complex math problem, search</td><td> Any</td><td> Multiprocessing</td>

</tr>

<tr>

<td>IO</td><td> Network connection, file operation </td><td> &lt; 1,000 </td><td> Multithreading</td>

</tr>

<tr>

<td>IO</td><td> Network connection, file operation </td><td> &gt; 1,000 </td><td> Multiprocessing + multithreading </td>

</tr>

</table>



<p>Use this table to choose an approach, and the scripts above to make quick work of even large jobs. Multi-core, multithreaded architectures mean no one should have to suffer through painful sequential execution anymore. Python makes concurrency easy, so take advantage of it.</p>



<p id='fn1'><a class='fn' title='return to article' href='#fnref1'>&#x21a9;</a>&nbsp;I understand that <code>T = (h &#42; n)/t + n/t&#42;z + o</code> implies simultaneous execution, which is correct when using multiprocessing but not when using multithreading. Multithreaded programs run on a single core. Although the processor pauses and resumes threads so fast that it gives the impression of parallel execution, they do not execute in parallel. In this scenario, though, this is effectively a meaningless distinction. Multithreaded IO-bound tasks are essentially indistinguishable from multiprocessed ones, given an equal number of threads and cores.</p>



<p><a class='read_more_link' href='/blog/linear-python.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/my-electric-vehicle-wishlist.html">My Electric Vehicle Wishlist</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-22 08:03:35-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/22 08:03:35 EST</time>
<p>I spent a fair bit of time <a href="https://zacs.site/blog/tesla-cybertruck.html">knocking</a> electric vehicles <a href="https://zacs.site/blog/why-teslas-are-bad-at-towing.html">last month</a>, so I thought I would spend some time talking about the things I want to see in one.</p>

<p>A business writer once made a great point about the cost of poaching customers: a competitor could not just make a product as good as the one it wanted to replace. No one would bother switching. Overcoming that required building a markedly better product. When it comes to electric vehicles, something needs to push me over that edge. Their vast potential raises the bar further: I have little interest in a good electric vehicle, because I know the technology enables exceptional ones. I bring this up as context with which to frame the criteria below, lest they seem unfair. A new generation of auto makers has the burden of both convincing me to switch, and taking full advantage of this new technology.  </p>

<p>I want to see three things in an electric vehicle. Done well, a car with these features might push me to get rid of <a href="https://zacs.site/blog/choosing-an-adventure-rig.html">my 4Runner</a>. </p>

<ul>
<li><strong>Interior volume.</strong> Most electric vehicles trade an engine bay for a second trunk. I want to see that volume become more usable cabin space for passengers, that could also store cargo. </li>
<li><strong>Off-road capability.</strong> Low center of gravity, independent motors, and independent suspension should make for an exceptional off-road vehicle with unprecedented on-road manners. </li>
<li><strong>Range.</strong> I want to see a huge range increase over today&#8217;s electric vehicles for two reasons. First, <a href="https://zacs.site/blog/why-teslas-are-bad-at-towing.html">it takes a ton of energy to tow</a>. I cannot accept losing half my range because I need to hook up a trailer, which means the batteries need to store a lot more energy, which means the non-towing range of the vehicle should go way up. I also want to see this as an indicator that the vehicle can maintain significant power reserves as a prerequisite for long-term backcountry expeditions, during which I may go several days without recharging.</li>
</ul>

<p>Build a car with three qualities, and I may trade in the 4Runner I plan to keep for another decade. As for what it should look like, the efficient use of space in a vehicle like the <a href="https://www.allpar.com/cars/concepts/jeep/FC.html">Jeep Forward Control</a> lends itself to a massive cabin that could hold many passengers or a great deal of cargo, and the modular design of the <a href="https://www.neuronev.co/new-products/t-one-p-gyrwr">Neuron EV</a> would make satisfying any buyer&#8217;s needs easy. Trade Neuron&#8217;s strange, elongated truck-like design for something more Forward Control-esque but keep the low-profile electric drivetrain, and I think you would have a winner. That&#8217;s what it will take to get me to switch.</p>


<p><a class='read_more_link' href='/blog/my-electric-vehicle-wishlist.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/trading-conditioning-for-strength.html">Trading Conditioning for Strength</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-13 08:06:31-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/13 08:06:31 EST</time>
<p>I talked about <a href="https://zacs.site/blog/my-road-to-weightlifting.html">my road to weightlifting</a> a few months ago, and then the price of <a href="https://zacs.site/blog/trading-strength-for-conditioning.html">trading strength for conditioning</a>. Today I want to look at the other side of that coin. After regaining the ground I lost in February and March of last year, I want to talk about the challenges of trading conditioning for strength.  </p>

<p>Most people do not know how to build strength. I saw this in high school and college, and see it today in the Army, too. They start by going about it wrong, which leads to poor results. Some just try harder, and get hurt. Both ways, they end up settling for weakness&#160;&#8212;&#160;and a few even try to justify it. &#8220;I could never deadlift 400 pounds anyway.&#8221; &#8220;Squatting more than three plates is just for show.&#8221; &#8220;There&#8217;s no reason to bench more than like 225.&#8221; I&#8217;ve heard it all, and it&#8217;s all a lie. I do not want to focus on the right approach, though, or poke holes in those excuses. For now, I will assume you have both the will and the way to become strong, so I can talk about some of the consequences of that decision.  </p>

<p>As I said <a href="https://zacs.site/blog/trading-strength-for-conditioning.html">last time</a>, moving from one end of the fitness spectrum to the other means opening yourself up to injury. A body built by conditioning has the endurance to push through heavy lifts, but lacks the power to back it up, and the durability to keep from breaking at the point of failure. I faced this again after the APFT. After spending March retraining myself to run, switching back to weightlifting almost caused some bad injuries. It will take time to recondition your body, so take that slow. Many jump right in and get hurt&#160;&#8212;&#160;like I almost did&#160;&#8212;&#160;and then never try again. Do not ease into it for long, but do not gloss over this step, either.  </p>

<p>High endurance mixed with low power and durability also tends to cause strength training to feel ineffective. Used to a few high repetition sets, switching to many low repetition sets spread out over a long period may seem easy at first. Many give up too soon and then fall back on their old ways. Again, it will take time to recondition your body. Once you make the switch, though, you will begin to see a marked change in your workouts. Do not use reconditioning as an excuse for easy workouts, but understand that it does take time to feel the effects of hard weightlifting.  </p>

<p>As you start building strength, you can also expect to lose conditioning&#160;&#8212;&#160;slowly at first, and then all at once. Making significant progress in one area means losing ground in the other. Your body will try to hold onto that endurance for a while, but will soon accept trading it for power. That point marks the beginning of a period of explosive growth. After the APFT, I added ten to twenty pounds to my bench press, squat, and deadlift each week for over a month. Progress slowed once I reached my pre-conditioning plateau, but even then it did not stop. Committing to strength training, and sticking with it through your body learning to cope with this new type of stress, yields remarkable growth.  </p>

<p>Although you can fuel this growth with a normal diet, it will slow your progress. Building strength means adding muscle, which your body cannot do without an excess of fuel. Most people over think this: just eat a lot of food, often. As long as you work hard for long periods of time, that food will turn into muscle.  </p>

<p>Because strength training takes so much more time and effort than conditioning, making this switch will also leave you with less time, and far less energy to make good use of it. Even at the height of my conditioning, when I would run or ruck miles a day, my workouts lasted for about an hour. Today I spend almost twice that long in the gym, working much harder than I ever have before. Plan for this. If you do not, you will both limit your potential and slow your progress.  </p>

<p>Get into strength training with eyes wide open. Avoid getting hurt by taking it slow at first, but do not let a lack of progress discourage you. Take some time to retrain your body, fuel it well, and then get after it. It takes a lot of time and energy, but the hard-won rewards make it worth the struggle.</p>


<p><a class='read_more_link' href='/blog/trading-conditioning-for-strength.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/rivians-real-edge.html">Rivian's Real Edge</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-08 07:41:46-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/08 07:41:46 EST</time>
<p>James Temple, writing for MIT Technology Review in <a href="https://www.technologyreview.com/s/614995/the-rivian-pickups-real-edge-over-teslas-cybertruck-isnt-its-battery/"><em>The Rivian pickup&#8217;s real edge over Tesla&#8217;s Cybertruck isn&#8217;t its battery</em></a>, emphasis mine: </p>

<blockquote>
<p>&#8220;[Rivian&#8217;s] vehicles, as well as Amazon&#8217;s and Ford&#8217;s, will all be built upon [Rivian&#8217;s] so-called <a href="https://rivian.com/technology/">&#8216;skateboard&#8217; chassis</a>. It packages together the battery, suspension, braking system, and mechanical components <strong>all below the height of the wheels</strong> ... By providing such a platform technology, Rivian is positioning itself as a sort of Microsoft to Tesla&#8217;s Apple&#160;&#8212;&#160;hoping it can capture a larger share of the market.&#8221;</p>
</blockquote>

<p>I have written little about electric vehicles. In general, the present state of battery technology makes them <a href="https://zacs.site/blog/expedition-rigs.html#Electric">unsuitable</a> for backcountry expeditions. More specifically, <a href="https://zacs.site/blog/bollinger-to-unveil-electric-off-roaders.html">Bollinger</a>&#8217;s <a href="https://zacs.site/blog/bollinger-125000.html">high price tag</a> precludes its vehicles from going mainstream, Rivian played it safe with <a href="https://www.motor1.com/news/350210/rivian-r1t-electric-camper-overland-expo/">an old design revamped for fancy aspirational campers</a>, and while <a href="https://zacs.site/blog/hot-takes-on-teslas-cybertruck.html">Tesla</a> <a href="https://zacs.site/blog/tesla-cybertruck.html">did something interesting</a>, the Cybertruck <a href="https://zacs.site/blog/why-teslas-are-bad-at-towing.html">cannot do truck things</a>. I look forward to the day these become <a href="https://zacs.site/blog/expedition-rigs.html">viable backcountry adventure platforms</a>, but that day has not yet come. The two passages above, though, reminded me of something Matt Stoller said in <a href="https://mattstoller.substack.com/p/what-is-a-billionaire"><em>What Is a Billionaire?</em></a>:</p>

<blockquote>
<p>&#8220;Gates didn&#8217;t at first think operating systems were that important, and he wanted to use the OS to sell programming languages. But soon he realized that the operating system was a key on-ramp to the personal computer, a tollbooth or chokepoint for all other software. ... He built a licensing regime that charged personal computer makers a fee for installing his operating system. More importantly, his licensing regime effectively required computer makers to pay a fee if they installed a rival operating system. Through a coercive partnership with computer makers, Gates imposed a tax on the entire industry, including his competitors, much as Rockefeller had using his relationship with railroads.&#8221;</p>
</blockquote>

<p>Rivian has positioned itself to become a similar key on-ramp, except to electric vehicles&#160;&#8212;&#160;first for Amazon and Ford, but perhaps more in the future. From the outside looking in, it seems the company <a href="https://rivian.com/technology/">has the flexibility</a> to become an electric vehicle-enabling behemoth, and the <a href="https://www.kbb.com/car-news/rivian/2100006867/">price</a>; whether it can grow to, and operate at, that scale, though, remains to be seen. If Rivian can do this, and do it better than its competitors long enough to beat them out, it could find itself in the same powerful and lucrative position Bill Gates put Microsoft in years ago. Rivian&#8217;s enthusiasm for its truck and SUV, the R1T and R1S, make me hesitant to say it will go this route. As we have seen, though, priorities change and fortunes are made. The company has a long road ahead of it, but the possible upside if it chooses this course is enormous.</p>


<p><a class='read_more_link' href='/blog/rivians-real-edge.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://tonsky.me/blog/good-times-weak-men/">Good times create weak men</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-07 07:04:48-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/07 07:04:48 EST</time>
<p>Nikita Prokopov, on the growing complexity of software and the shrinking number of people who understand it:</p>

<blockquote>
<p>&#8220;In programming, we are developing abstractions at an alarming rate. When enough of those are stacked, it becomes impossible to figure out or control what&#8217;s going on down the stack. ... Docker and Electron are the most hyped new technologies of the last five years. Both are not about improving things, figuring out complexity or reducing it. Both are just compromised attempts to hide accumulated complexity from developers because it became impossible to deal with.&#8221;</p>
</blockquote>

<p>I saw this in college, when even Computer Science students favored complex and bloated frameworks over their own code. I make a concerted effort to counter it in my own projects: <a href="/projects.html#firstCrack">First Crack</a>, the custom blog engine behind this site, uses vanilla Python 2 or 3 and has no dependencies. <a href="https://blog.codinghorror.com/please-dont-learn-to-code/">If you</a> decide <a href="https://johnkurkowski.com/posts/dont-learn-to-code-learn-to-program-but-come-back-in-10-years/">to code</a>, <a href="http://codefol.io/posts/no-such-thing-as-knowing-coding-all-the-way-to-the-bottom/">you don&#8217;t have to start with C</a>&#160;&#8212;&#160;but you should learn it. I resisted this during college, but two years into my career, I have come around: the lower you go, the better you will understand things higher in the stack. With greater understanding comes an increased ability to influence those things, which, in turn, will make you better at your job.</p>

<p>Michal Charemza brought up another good point in <a href="https://charemza.name/blog/posts/abstractions/http/http-guide-for-developers/"><em>Mini HTTP guide for developers</em></a>:</p>

<blockquote>
<p>&#8220;Frameworks often hide/abstract parts of HTTP away. I think this is often a bit of a shame: it hides what&#8217;s possible with HTTP, and so can lead to effects on engineering decisions.&#8221;</p>
</blockquote>

<p>By learning to use frameworks instead of the tools and protocols they implement, developers not only miss out on foundational knowledge that will help them become better at their job, but also hamstring themselves to the subset of features the frameworks’ creators’ felt important enough to enable. Expanding a project beyond that expected use case will require diving into those low-level tools and protocol—-which, again, you do not have to start with, but you should learn at some point.</p>


<p><a class='read_more_link' href='/blog/good-times-create-weak-men.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://mattstoller.substack.com/p/trumps-surprising-embrace-of-industrial">Trump's Surprising Embrace of Industrial Policy to Fight China</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-06 08:00:35-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/06 08:00:35 EST</time>
<p>I took some time to <a href="https://zacs.site/blog/updates-to-my-morning-and-evening-reads.html">update</a> <a href="https://zacs.site/blog/my-morning-reads.html"><em>Keeping Up with Current Events</em></a> and <a href="https://zacs.site/blog/my-evening-reads.html"><em>My Evening Reads</em></a> over the holidays, which involved adding Matt Stoller&#8217;s excellent newsletter <em>BIG</em> to the list of sources that help me stay informed. His most recent issue, <a href="https://mattstoller.substack.com/p/trumps-surprising-embrace-of-industrial"><em>Trump&#8217;s Surprising Embrace of Industrial Policy to Fight China</em></a>, is a prime example of the shrewd analysis that makes it so interesting. This issue is a great way to start the new year, and new subscribers will find his roundup of 2019&#8217;s best posts at its beginning helpful, too.</p>


<p><a class='read_more_link' href='/blog/big-china.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://hbr.org/2019/12/what-happens-when-your-career-becomes-your-whole-identity">What Happens When Your Career Becomes Your Whole Identity</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-03 06:48:28-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/03 06:48:28 EST</time>
<p>Janna Koretz, writing for Harvard Business Review, on an interesting phenomenon called enmeshment. Working in a profession known to encourage and reward workaholism, I see this often&#160;&#8212;&#160;and work to counter it where possible.</p>


<p><a class='read_more_link' href='/blog/enmeshment.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://www.curbed.com/2019/9/18/20870828/rv-camper-repairs-poor-quality">Why are RV's so poorly made?</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-02 06:42:26-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/02 06:42:26 EST</time>
<p>Andrew Zaleski digs into the factors contributing to the RV market&#8217;s notorious lack of quality. I thought a lot about getting <a href="https://zacs.site/blog/expedition-rigs.html">an RV</a> instead of my first house, but this pushed me away from buying an RV then and ensured that when I do decide to go that route, <a href="/projects.html#lmtvRV">I will build it myself</a>.</p>


<p><a class='read_more_link' href='/blog/why-are-rvs-so-poorly-made.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/updates-to-my-morning-and-evening-reads.html">Updates to My Morning and Evening Reads</a>
</h2>
<time class='dt-published' id='article_time' datetime="2020-01-01 09:17:12-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2020.html">2020</a>/<a href="/blog/2020-01.html">01</a>/01 09:17:12 EST</time>
<p>I spent enough time Internet-less this holiday season that I had a chance to catch up on a few administrative tasks. One of those involved updating <a href="https://zacs.site/blog/my-morning-reads.html"><em>Keeping Up with Current Events</em></a> and <a href="https://zacs.site/blog/my-evening-reads.html"><em>My Evening Reads</em></a> to reflect new sites, feeds, and newsletters I now follow, as well as those I no longer read. I work hard to educate myself and stay informed, and I encourage you to check those posts out as a great starting point to doing the same for yourself.</p>


<p><a class='read_more_link' href='/blog/updates-to-my-morning-and-evening-reads.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="original u-url" href="/blog/first-crack-release-notes-1219.html">First Crack Release Notes, December 2019</a>
</h2>
<time class='dt-published' id='article_time' datetime="2019-12-31 06:41:36-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2019.html">2019</a>/<a href="/blog/2019-12.html">12</a>/31 06:41:36 EST</time>
<p>I spent a lot of time on <a href="/projects.html#firstCrack">First Crack</a> this month. Writing <a href="https://zacs.site/blog/first-crack-release-notes-1119.html">last month&#8217;s</a> release notes pushed me to stop dragging my feet, and I made some great progress. </p>

<h2 class="headers" id="DecemberActivity">December Activity<span>&nbsp;<a href="#DecemberActivity">#</a></span></h2>

<p>I talked about the problems multi-threading caused in <a href="https://zacs.site/blog/first-crack-release-notes-1119.html">last month&#8217;s post</a>, and my band-aid fix: instantiating a Markdown parser for each file. This bumped First Crack&#8217;s sub-second runtime up over the one second mark, and just felt lazy, so I set out to fix it in early December.</p>

<p>I first binned the files by year, then fed each bin to its own core. First Crack rebuilt HTML files as needed, sorted them by time, then went back over them to extract their title and content for the blog and archives pages. I chose this approach because I had to build those index pages from newest to oldest, and it allowed the engine to do most of the file operations&#160;&#8212;&#160;and all the Markdown parsing&#160;&#8212;&#160;up front, as fast as possible, and without regards to order. This rewrite ended up running <em>slower</em> than the original, though, and had its fair share of strange bugs<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup>. I played around with it for the rest of the weekend, but the rewrite I had such hope for just never made the cut.</p>

<p>I did find a few ways to improve performance during the course of that rewrite, though, which ended up cutting runtime by up to <em>half</em>. Check out the GIF below, via <a href="https://github.com/faressoft/terminalizer/blob/master/README.md">Terminalizer</a>, which shows the latest version of First Crack clearing and then building my entire site ten times:</p>

<div class='image'><img src='/assets/images/system/runtime.gif' alt='First Crack runtime, 10 runs' title='First Crack runtime, 10 runs' loading='lazy' /></div>

<p>First Crack rebuilds the entire site in as much as 0.81 seconds, and as little as 0.64&#160;&#8212;&#160;its best yet. De-duplicating work across a few methods helped, but for the most part that massive speed boost came from slashing I/O operations. To build the <a href="/archives.html">Post Archives</a> page and <a href="/rss.xml">RSS feed</a>, the engine used to sort every file, read a certain number of paragraphs based on article type, open the target, append that content, close both, and then repeat until it got through every post. It now does this in batches, which got rid of almost 1,000 file operations on <code>archives.html</code> and <code>rss.xml</code> each. This had the greatest impact on First Crack&#8217;s runtime in December, by far.</p>

<br />

<p>Although <a href="https://jeffhuang.com/designed_to_last/">Jeff Huang&#8217;s recent push for developers to write well-structured HTML to help novies learn</a> did give me pause, I also gave up on &#8220;pretty printing&#8221; in December. Minifying the template alone shrank its file size by almost 25%. Applying this to the rest of the build process shaved almost 1KB off the average file size. As a result, First Crack takes less time to build smaller files that then load faster for you&#160;&#8212;&#160;a win all around. All DOM inspection tools reformat HTML anyway, so I&#8217;ll take the performance boost with no real downside.</p>

<h2 class="headers" id="FeatureRoadmap">Feature Roadmap<span>&nbsp;<a href="#FeatureRoadmap">#</a></span></h2>

<p>Going forward, I plan to focus on these (mostly minor) features.</p>

<h3 class="headers" id="ReleaseMarkdownParser">Release Markdown Parser<span>&nbsp;<a href="#ReleaseMarkdownParser">#</a></span></h3>

<p>I still want to release my Markdown parser as its own project. I still have some bugs to work out, though, I want to go public with greater coverage of the spec, and I would like to add the ability to parse multi-line strings and entire files at once.</p>

<h3 class="headers" id="PublishImplementationofMarkdownSpec">Publish Implementation of Markdown Spec<span>&nbsp;<a href="#PublishImplementationofMarkdownSpec">#</a></span></h3>

<p>I still want to outline the peculiarities of my implementation of the Markdown spec. This would cover weird edge cases for the most part, but documenting these shortfalls would still have value so that those who use my engine will have some sort of explanation for why their article looks weird, and so that I may one day fix them. I made some progress here this month, but not enough for a finished product.</p>

<h3 class="headers" id="ImproveDocumentation">Improve Documentation<span>&nbsp;<a href="#ImproveDocumentation">#</a></span></h3>

<p>As always, I could do more here. Again, a few of the ways I think I can improve the README:</p>

<ul>
<li>Performance graphs of First Crack&#8217;s back-end performance versus other, similar engines. At less than two seconds to build a website of over one thousand pages, I want to highlight this.</li>
<li>Performance graphs of the web pages First Crack builds versus the pages common content management systems build.</li>
<li>Screenshots. This site is a live demo of the engine, but I like the idea of having a few pictures in there, too.</li>
</ul>

<p>As always, I look forward to the work ahead.</p>

<p id='fn1'><a class='fn' title='return to article' href='#fnref1'>&#x21a9;</a>&nbsp;How about this one: if the beta engine creates a new Markdown purser for each file, a seemingly random subset of 2019 posts do not get parsed. Instead, the original Markdown appears in the output HTML files as if copied straight from the source. If the engine creates a new parser for each month, more files go unparsed, this time from other years as well. If each core gets one parser to handle the entire year, the parser skips over almost 10% of the source files. Weird.</p>


<p><a class='read_more_link' href='/blog/first-crack-release-notes-1219.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://jeffhuang.com/designed_to_last/">This Page is Designed to Last</a>
</h2>
<time class='dt-published' id='article_time' datetime="2019-12-30 19:01:33-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2019.html">2019</a>/<a href="/blog/2019-12.html">12</a>/30 19:01:33 EST</time>
<p>Jeff Huang, echoing a point I made in <a href="https://zacs.site/blog/own-your-platform.html"><em>Own Your Platform</em></a>, in his piece on the importance of building websites that stand the test of time:</p>

<blockquote>
<p>&#8220;I&#8217;ve recommended my students to push websites to Heroku, and publish portfolios on Wix. Yet every platform with irreplaceable content dies off some day. Geocities, LiveJournal, what.cd, now Yahoo Groups. One day, Medium, Twitter, and even hosting services like GitHub Pages will be plundered then discarded when they can no longer grow or cannot find a working business model.&#8221;</p>
</blockquote>

<p>And then, later, he echoes a point I made in <a href="https://zacs.site/blog/how-to-own-your-platform.html"><em>How to Own Your Platform</em></a>, about the vulnerable position relying on trendy third-party frameworks puts you in: </p>

<blockquote>
<p>&#8220;... a growing set of libraries and frameworks are making the web more sophisticated but also more complex. First came jquery, then bootstrap, npm, angular, grunt, webpack, and more. If you are a web developer who is keeping up with the latest, then that&#8217;s not a problem. But if not, maybe you are an embedded systems programmer or startup CTO or enterprise Java developer or chemistry PhD student, sure you could probably figure out how to set up some web server and toolchain, but will you keep this up year after year, decade after decade? Probably not, and when the next year when you encounter a package dependency problem or figure out how to regenerate your html files, you might just throw your hands up and zip up the files to deal with &#8216;later&#8217;. Even simple technology stacks like static site generators (e.g., Jekyll) require a workflow and will stop working at some point. You fall into npm dependency hell, and forget the command to package a release.&#8221;</p>
</blockquote>

<p>Run your website, and <a href="/projects.html#firstCrack">own the production stack</a>. Jeff has some some good ideas, but do not paper over poor back-end design with good front-end work. <a href="https://zacs.site/blog/own-your-platform.html">Own your platform</a>, so that you can ensure both will stand the test of time.</p>


<p><a class='read_more_link' href='/blog/this-page-is-designed-to-last.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>
<article>
<h2 id='article_title' class='p-name'>
<a class="linkpost u-url" href="https://foreignpolicy.com/2019/12/04/thomas-james-interview-space-force-commander-no-one-wins/">'No One Wins if War Extends Into Space'</a>
</h2>
<time class='dt-published' id='article_time' datetime="2019-12-12 07:41:09-0400" pubdate="pubdate">By <link rel="author" class="p-author h-card">Zac J. Szewczyk</link> on <a href="/blog/2019.html">2019</a>/<a href="/blog/2019-12.html">12</a>/12 07:41:09 EST</time>
<blockquote>
<p>&#8220;We&#8217;re at an inflection point today in the idea of space being developed as its own domain. When you look at the threats that we have today, there&#8217;s some similarity to what we had in the &#8216;80s. That waned in the &#8217;90s and that led us to the idea of space as an uncontested area, so we designed space architecture based off the fact that we wouldn&#8217;t really be threatened in space. Today you&#8217;ve got a pretty much more aggressive threat. So that space area of operations is the area that we focus on for protecting and defending critical assets as we look at the growing threat from our adversaries.&#8221;</p>
</blockquote>

<p>Replace &#8220;space&#8221; with &#8220;cyberspace&#8221;, and BG James could have said this twenty years ago about the fifth domain.</p>


<p><a class='read_more_link' href='/blog/no-one-wins.html'>Read more</a><span class='logo'>&#x24E9;</span></p>
</article>

        </main>
        <footer>
            <p>
                Follow me on <a href="http://twitter.com/zacjszewczyk">Twitter</a>, <a href="https://www.instagram.com/zacjszewczyk/">Instagram</a>, or subscribe to my <a href="/rss.xml">RSS</a> feed.
            </p>
            <p>
                © 2012-2020 Zachary Szewczyk.
            </p>
            <p>
                This work is licensed under a <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">Creative Commons Attribution 4.0 International License</a>.
            </p>
        </footer>
        <div id="lg"></div>
        <div id="rg"></div>
    </body>
    <link rel="manifest" href="/assets/manifest.json">
</html>